# Deep learning materials

This is a curated repository of materials for deep learning.

# Table of Contents

- [Courses](#courses)
- [Tutorials](#tutorials)
- [Curated lists](#curated-lists)
- [Papers](#papers)
- [Books](#books)
- [Reports](#reports)
- [Models](#models)
- [Benchmarks](#benchmarks)
- [Datasets](#datasets)

## <a name='Courses'></a>Courses
- [Introduction to Deep Learning (MIT)](http://introtodeeplearning.com/)
- [Mathematical Engineering of Deep Learning](https://deeplearningmath.org/)
- [Generative AI for beginners](https://microsoft.github.io/generative-ai-for-beginners/#/)
- Stanford Cheatsheets [Machine Learning](https://stanford.edu/~shervine/teaching/cs-229/) [Deep Learning](https://stanford.edu/~shervine/teaching/cs-230/)
- Courses by Sebastian Raschka [Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html) [Machine Learning](https://sebastianraschka.com/blog/2021/ml-course.html) [Deep Learning Fundamentals](https://lightning.ai/courses/deep-learning-fundamentals/)

## <a name='Tutorials'></a>Tutorials
- [Build a Large Language Model (From Scratch)](https://github.com/rasbt/LLMs-from-scratch)
- [GPT in 60 lines of NumPy](https://jaykmody.com/blog/gpt-from-scratch/)
- [Implementing Mixtral with Neural Circuit Diagrams](https://github.com/vtabbott/Neural-Circuit-Diagrams/blob/main/mixtral.ipynb)

## <a name='Curated lists'></a>Curated lists
- [The Incredible PyTorch](https://github.com/ritchieng/the-incredible-pytorch/)

## <a name='Papers'></a>Papers
- Role play with large language models (2023) [Nature.com](https://www.nature.com/articles/s41586-023-06647-8) [arXiv](https://arxiv.org/pdf/2305.16367.pdf)
- Attention is All You Need (2017) [arXiv v7 (2023)](https://arxiv.org/pdf/1706.03762.pdf)
- OLMo: Accelerating the Science of Language Models (2024) [arXiv](https://arxiv.org/pdf/2402.00838.pdf)

## <a name='Books'></a>Books
- [Understanding Deep Dearning (2023)](https://udlbook.github.io/udlbook/)
- [Deep Learning](https://www.deeplearningbook.org/)
- [Hands-On Machine Learning with R](https://bradleyboehmke.github.io/HOML/index.html)
- [Interpretable Machine Learing](https://christophm.github.io/interpretable-ml-book/)

## <a name='Reports'></a>Reports
- [The State of Competitive Machine Learning (2023)](https://mlcontests.com/state-of-competitive-machine-learning-2023/?es_id=4476a44c3d#competitive-ml-landscape)

## <a name='Models'></a>Models
- Moondream - tiny vision language model [web](https://moondream.ai/) [Github](https://github.com/vikhyat/moondream)
- BioMistral - pretrained LLM models for biomedical domain [arXiv](https://arxiv.org/pdf/2402.10373.pdf) [HuggingFace](https://huggingface.co/BioMistral/BioMistral-7B)

## <a name='Benchmarks'></a>Benchmarks
- [Nicolas Carlini's benchmark of 100 tests for LLM's](https://nicholas.carlini.com/writing/2024/my-benchmark-for-large-language-models.html)

## <a name='Datasets'></a>Datasets
- Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research [arXiv](https://arxiv.org/pdf/2402.00159.pdf) [HuggingFace](https://huggingface.co/datasets/allenai/dolma)

